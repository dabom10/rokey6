{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lcApS9Y0DKeCnN9kzdRT4brQWuR5zj43","timestamp":1761633379833}],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torch numpy matplotlib seaborn scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKa1HwUCiGFp","executionInfo":{"status":"ok","timestamp":1761633418625,"user_tz":-540,"elapsed":7169,"user":{"displayName":"김다봄","userId":"02209919459503367304"}},"outputId":"40caab5c-e6cc-4f66-8e77-ca1a98154ec6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1yF5XWxnebp","executionInfo":{"status":"ok","timestamp":1761712600765,"user_tz":-540,"elapsed":16288,"user":{"displayName":"김다봄","userId":"02209919459503367304"}},"outputId":"22956aed-f5b3-47d8-8459-35d3c92cb37e"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","4차시 실습: 인공지능 개론 - 통합 실행\n","======================================================================\n","\n","[Part 1] 모델 정의 중...\n","모델 정의 완료\n","\n","[Part 2] 지도학습 - 분류와 회귀\n","분류 모델 학습 중...\n","분류 모델 학습 완료\n","회귀 모델 학습 중...\n","회귀 모델 학습 완료\n","\n","[Part 3] 비지도학습과 편향-분산\n","저장: result_clustering.png\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=2.35718e-21): result may not be accurate.\n","  return f(*arrays, *other_args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["저장: result_bias_variance.png\n","\n","[Part 4] K-Fold 교차검증\n","K-Fold 평균 Accuracy: 0.9320 (std: 0.0075)\n","\n","[Part 5] 평가 지표 계산\n","분류 성능: Acc=0.880, Prec=0.950, Rec=0.633, F1=0.760, AUC=0.960\n","저장: result_classification.png\n","회귀 성능: MAE=12.76, RMSE=15.62, R2=0.991\n","저장: result_regression.png\n","\n","[Part 6] ML 파이프라인 실행\n","\n","STEP 1: 문제 정의\n","  목표: 고객 이탈 예측 (F1 > 0.80)\n","\n","STEP 2: 데이터 준비\n","  Train: 700, Val: 150, Test: 150\n","\n","STEP 3: 베이스라인\n","  베이스라인 F1: 0.0000\n","\n","STEP 4: 모델 학습\n","  학습 완료\n","\n","STEP 5: 최종 평가\n","  테스트 F1: 0.7961\n","  베이스라인 대비: +0.7961\n","  목표 미달, 추가 개선 필요\n","\n","======================================================================\n","전체 실습 완료\n","======================================================================\n","\n","생성된 파일:\n","  1. result_clustering.png     - 군집화 결과\n","  2. result_bias_variance.png  - 편향-분산 트레이드오프\n","  3. result_classification.png - 분류 평가\n","  4. result_regression.png     - 회귀 평가\n","\n","모든 실습이 정상적으로 완료되었습니다.\n","======================================================================\n"]}],"source":["\"\"\"\n","4차시 실습 통합 실행 파일\n","모든 실습을 한 번에 실행할 수 있습니다.\n","\n","Part 1: 기본 설정 및 모델 정의\n","Part 2: 지도학습 (분류와 회귀)\n","Part 3: 비지도학습과 편향-분산\n","Part 4: K-Fold 교차검증\n","Part 5: 평가 지표 계산\n","Part 6: 전체 ML 파이프라인\n","\n","필수 라이브러리:\n","pip install torch numpy matplotlib seaborn scikit-learn\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.datasets import make_classification, make_regression, make_blobs\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures # 표준화(평균0, 분산=표준편차1)\n","from sklearn.metrics import ( # 사이킷런의 평가지표\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    confusion_matrix, roc_auc_score, roc_curve,\n","    mean_absolute_error, mean_squared_error, r2_score #r2_score=설명력\n",")\n","from sklearn.linear_model import Ridge\n","from sklearn.cluster import KMeans # 군집화cluster에 k-means 방법 많이 씀\n","\n","# 재현성을 위한 시드 고정(누가 해도 똑같이 반복된다)\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# 한글 깨짐 방지\n","plt.rcParams['axes.unicode_minus'] = False\n","\n","\n","print(\"=\" * 70)\n","print(\"4차시 실습: 인공지능 개론 - 통합 실행\")\n","print(\"=\" * 70)\n","\n","\n","# =====================================================================\n","# Part 1: 모델 정의\n","# =====================================================================\n","print(\"\\n[Part 1] 모델 정의 중...\")\n","\n","class BinaryClassifier(nn.Module):    #nn.Module: pytorch에서 상속받겠구나 생각해야됨\n","    \"\"\"이진 분류용 다층 퍼셉트론\"\"\"\n","    def __init__(self, input_dim): # 각각의 속성은 열로 들어간다(dimention=차원)\n","        super(BinaryClassifier, self).__init__()\n","        self.layer1 = nn.Linear(input_dim, 64) # 인풋데이터(input_dim)을 64개로 만들어준다\n","        self.layer2 = nn.Linear(64, 32) # input 64개 들어와서 32개 만듦(은닉층의 노드=속성)\n","        self.layer3 = nn.Linear(32, 1)\n","        self.relu = nn.ReLU() # 사용할 활성화 함수(은닉층)\n","        self.dropout = nn.Dropout(0.3) # 과적합 방지. 랜덤하게 30% 삭제. 학습할때만.테스트데이터 건들지마.\n","        self.sigmoid = nn.Sigmoid()\n","    # 순전파\n","    def forward(self, x):\n","        x = self.relu(self.layer1(x)) # 64개 노드 레이어\n","        x = self.dropout(x)\n","        x = self.relu(self.layer2(x)) # 32개 노드 레이어\n","        x = self.dropout(x)\n","        x = self.sigmoid(self.layer3(x)) # 마지막에 시그모이드 :0.5 이상이면 1~ 이진 분류니까(출력층)\n","        return x\n","\n","\n","class Regressor(nn.Module):\n","    \"\"\"회귀용 다층 퍼셉트론\"\"\"\n","    def __init__(self, input_dim):\n","        super(Regressor, self).__init__()\n","        self.network = nn.Sequential(\n","            nn.Linear(input_dim, 64), # 층\n","            nn.ReLU(), # 다른 층으로 보낼 때 ReLU 통과\n","            nn.Linear(64, 32), # 층2\n","            nn.ReLU(),\n","            nn.Linear(32, 1) # 층3\n","        )\n","\n","    def forward(self, x):\n","        return self.network(x)\n","\n","print(\"모델 정의 완료\")\n","\n","\n","# =====================================================================\n","# Part 2: 지도학습\n","# =====================================================================\n","print(\"\\n[Part 2] 지도학습 - 분류와 회귀\")\n","\n","# 분류 데이터 생성 및 학습\n","X_class, y_class = make_classification( # 분류하는애를 생성하겠다\n","    n_samples=1000, n_features=20, n_informative=15, # 속성 20개 중에 피쳐 15개 남는거 5개\n","    n_redundant=5, weights=[0.7, 0.3], random_state=42\n",")\n","\n","# train:test = 6:4\n","X_train_c, X_temp_c, y_train_c, y_temp_c = train_test_split(\n","    X_class, y_class, test_size=0.4, random_state=42, stratify=y_class\n","    #  stratify=y_class : sork tjfwjdgks zmffotmeofh ..(??)\n",")\n","# train:test = 5:5\n","X_val_c, X_test_c, y_val_c, y_test_c = train_test_split(\n","    X_temp_c, y_temp_c, test_size=0.5, random_state=42, stratify=y_temp_c\n",")\n","\n","# 정규화(표준화: 평균0 분산1) 스케일링\n","scaler_c = StandardScaler()\n","X_train_c_scaled = scaler_c.fit_transform(X_train_c)\n","X_val_c_scaled = scaler_c.transform(X_val_c)\n","X_test_c_scaled = scaler_c.transform(X_test_c)\n","\n","# 스케일링 된 일반적인 데이터->tensor로 변환 for 머신러닝\n","X_train_c_t = torch.FloatTensor(X_train_c_scaled)\n","y_train_c_t = torch.FloatTensor(y_train_c).unsqueeze(1)\n","X_val_c_t = torch.FloatTensor(X_val_c_scaled)\n","y_val_c_t = torch.FloatTensor(y_val_c).unsqueeze(1)\n","\n","model_class = BinaryClassifier(input_dim=20)\n","criterion = nn.BCELoss() # binary class 엔트로피\n","optimizer = optim.Adam(model_class.parameters(), lr=0.001)\n","\n","print(\"분류 모델 학습 중...\")\n","best_val_loss = float('inf') # 초깃값 무한대infinity로 둠\n","# for best loss값을 앞전 loss값과 비교해서 구하기 때문에\n","patience_counter = 0\n","best_model_state = None\n","\n","# 훈련\n","for epoch in range(100):\n","    model_class.train()\n","    # 훈련 모드로 진입\n","    optimizer.zero_grad()\n","    # 최적화 초기화\n","    outputs = model_class(X_train_c_t) # = yhat\n","    # 예측값(모델이 예측)\n","    loss = criterion(outputs, y_train_c_t)\n","    # 손실 계산(예측값 ,실제값)\n","    loss.backward()\n","    # 역전파\n","    optimizer.step()\n","    # 학습률(learning rate) 활용, 학습 >> 손실 줄이기 위해서\n","    # w(next step) - w(current step) - lf (diff f(x)/diff(xtr))\n","\n","    # 평가\n","    model_class.eval()\n","    with torch.no_grad(): # 중요\n","        val_outputs = model_class(X_val_c_t)\n","        val_loss = criterion(val_outputs, y_val_c_t)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        patience_counter = 0\n","        best_model_state = model_class.state_dict()\n","    else:\n","        patience_counter += 1\n","\n","    if patience_counter >= 10:\n","        break\n","\n","model_class.load_state_dict(best_model_state)\n","print(\"분류 모델 학습 완료\")\n","\n","# 회귀 데이터 생성 및 학습\n","X_reg, y_reg = make_regression(\n","    n_samples=800, n_features=10, n_informative=8,\n","    noise=10.0, random_state=42\n",")\n","\n","X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n","    X_reg, y_reg, test_size=0.2, random_state=42\n",")\n","\n","scaler_r = StandardScaler()\n","X_train_r_scaled = scaler_r.fit_transform(X_train_r)\n","X_test_r_scaled = scaler_r.transform(X_test_r)\n","\n","X_train_r_t = torch.FloatTensor(X_train_r_scaled)\n","y_train_r_t = torch.FloatTensor(y_train_r).unsqueeze(1)\n","\n","# 예측모델\n","model_reg = Regressor(input_dim=10)\n","criterion_reg = nn.MSELoss()\n","optimizer_reg = optim.Adam(model_reg.parameters(), lr=0.01)\n","\n","print(\"회귀 모델 학습 중...\")\n","for epoch in range(100):\n","    model_reg.train()\n","    optimizer_reg.zero_grad()\n","    outputs = model_reg(X_train_r_t)\n","    loss = criterion_reg(outputs, y_train_r_t)\n","    loss.backward()\n","    optimizer_reg.step()\n","\n","print(\"회귀 모델 학습 완료\")\n","\n","\n","# =====================================================================\n","# Part 3: 비지도학습과 편향-분산\n","# =====================================================================\n","print(\"\\n[Part 3] 비지도학습과 편향-분산\")\n","\n","# K-Means 군집화\n","# K-Means 군집화 (cluster_std = 표준편차)\n","# K-Means : 여러 요소들 중 center를 기준으로 묶음(군집화)\n","# -> 계속해서 중심점 하나로 잡기(중심점 찾기 = K-means)\n","# K를 몇개로 할거냐?가 중요\n","X_cluster, y_true_cluster = make_blobs(\n","    n_samples=300, centers=3, n_features=2,\n","    cluster_std=1.0, random_state=42\n",")\n","\n","kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n","y_pred_cluster = kmeans.fit_predict(X_cluster)\n","\n","plt.figure(figsize=(15, 5))\n","\n","plt.subplot(1, 3, 1)\n","plt.scatter(X_cluster[:, 0], X_cluster[:, 1],\n","            c=y_true_cluster, cmap='viridis',\n","            alpha=0.6, edgecolors='k', s=50)\n","plt.title('True Labels', fontsize=12)\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.colorbar()\n","plt.grid(alpha=0.3)\n","\n","plt.subplot(1, 3, 2)\n","plt.scatter(X_cluster[:, 0], X_cluster[:, 1],\n","            c=y_pred_cluster, cmap='plasma',\n","            alpha=0.6, edgecolors='k', s=50)\n","plt.scatter(kmeans.cluster_centers_[:, 0],\n","            kmeans.cluster_centers_[:, 1],\n","            c='red', marker='X', s=300,\n","            edgecolors='black', linewidths=2)\n","plt.title('K-Means Result', fontsize=12)\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","plt.colorbar()\n","plt.grid(alpha=0.3)\n","\n","plt.subplot(1, 3, 3)\n","cluster_counts = np.bincount(y_pred_cluster)\n","plt.bar(range(len(cluster_counts)), cluster_counts,\n","        color=['#440154', '#31688e', '#fde724'], edgecolor='black')\n","plt.title('Cluster Sizes', fontsize=12)\n","plt.xlabel('Cluster ID')\n","plt.ylabel('Count')\n","plt.grid(axis='y', alpha=0.3)\n","\n","plt.tight_layout()\n","plt.savefig('result_clustering.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","print(\"저장: result_clustering.png\")\n","\n","# 편향-분산 트레이드오프\n","np.random.seed(42)\n","X_bias = np.sort(np.random.rand(100, 1) * 10, axis=0)\n","y_bias = np.sin(X_bias).ravel() + np.random.randn(100) * 0.5\n","X_test_bias = np.linspace(0, 10, 200).reshape(-1, 1)\n","y_test_bias = np.sin(X_test_bias).ravel()\n","\n","degrees = [1, 3, 9, 20]\n","colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12']\n","\n","plt.figure(figsize=(16, 4))\n","\n","for idx, degree in enumerate(degrees):\n","    poly = PolynomialFeatures(degree=degree)\n","    X_poly = poly.fit_transform(X_bias)\n","    X_test_poly = poly.transform(X_test_bias)\n","\n","    model_bias = Ridge(alpha=0.01)\n","    model_bias.fit(X_poly, y_bias)\n","\n","    train_pred = model_bias.predict(X_poly)\n","    test_pred = model_bias.predict(X_test_poly)\n","\n","    train_mse = mean_squared_error(y_bias, train_pred)\n","    test_mse = mean_squared_error(y_test_bias, test_pred)\n","\n","    plt.subplot(1, 4, idx + 1)\n","    plt.scatter(X_bias, y_bias, alpha=0.5, s=30,\n","                color='gray', edgecolors='black')\n","    plt.plot(X_test_bias, y_test_bias, 'g--', linewidth=2.5)\n","    plt.plot(X_test_bias, test_pred, color=colors[idx], linewidth=2.5)\n","    plt.title(f'Degree {degree}\\nTrain: {train_mse:.3f} | Test: {test_mse:.3f}')\n","    plt.ylim(-2.5, 2.5)\n","    plt.grid(alpha=0.3)\n","\n","plt.tight_layout()\n","plt.savefig('result_bias_variance.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","print(\"저장: result_bias_variance.png\")\n","\n","\n","# =====================================================================\n","# Part 4: K-Fold 교차검증\n","# =====================================================================\n","print(\"\\n[Part 4] K-Fold 교차검증\")\n","\n","X_kfold, y_kfold = make_classification(\n","    n_samples=500, n_features=20, n_informative=15, random_state=42\n",")\n","\n","k = 5\n","kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n","fold_scores = []\n","\n","for fold, (train_idx, val_idx) in enumerate(kfold.split(X_kfold)):\n","    X_train_fold = X_kfold[train_idx]\n","    y_train_fold = y_kfold[train_idx]\n","    X_val_fold = X_kfold[val_idx]\n","    y_val_fold = y_kfold[val_idx]\n","\n","    scaler_fold = StandardScaler()\n","    X_train_fold = scaler_fold.fit_transform(X_train_fold)\n","    X_val_fold = scaler_fold.transform(X_val_fold)\n","\n","    X_train_fold_t = torch.FloatTensor(X_train_fold)\n","    y_train_fold_t = torch.FloatTensor(y_train_fold).unsqueeze(1)\n","    X_val_fold_t = torch.FloatTensor(X_val_fold)\n","\n","    model_fold = BinaryClassifier(input_dim=20)\n","    optimizer_fold = optim.Adam(model_fold.parameters(), lr=0.01)\n","    criterion_fold = nn.BCELoss()\n","\n","    for epoch in range(30):\n","        model_fold.train()\n","        optimizer_fold.zero_grad()\n","        outputs = model_fold(X_train_fold_t)\n","        loss = criterion_fold(outputs, y_train_fold_t)\n","        loss.backward()\n","        optimizer_fold.step()\n","\n","    model_fold.eval()\n","    with torch.no_grad():\n","        val_pred_prob = model_fold(X_val_fold_t).numpy().flatten()\n","        val_pred = (val_pred_prob > 0.5).astype(int)\n","\n","    accuracy = accuracy_score(y_val_fold, val_pred)\n","    fold_scores.append(accuracy)\n","\n","print(f\"K-Fold 평균 Accuracy: {np.mean(fold_scores):.4f} (std: {np.std(fold_scores):.4f})\")\n","\n","\n","# =====================================================================\n","# Part 5: 평가 지표\n","# =====================================================================\n","print(\"\\n[Part 5] 평가 지표 계산\")\n","\n","# 분류 평가\n","model_class.eval()\n","X_test_c_t = torch.FloatTensor(X_test_c_scaled)\n","\n","with torch.no_grad():\n","    y_pred_prob_c = model_class(X_test_c_t).numpy().flatten() # numpy로 전환->CPU 써야지/계산해야지 , flatten = 1차원 벡터로\n","    y_pred_c = (y_pred_prob_c > 0.5).astype(int) # 0.5 넘으면 1\n","\n","cm = confusion_matrix(y_test_c, y_pred_c)\n","accuracy = accuracy_score(y_test_c, y_pred_c)\n","precision = precision_score(y_test_c, y_pred_c, zero_division=0)\n","recall = recall_score(y_test_c, y_pred_c, zero_division=0)\n","f1 = f1_score(y_test_c, y_pred_c, zero_division=0) # zero_division=0: ZeroDivideError\n","auc = roc_auc_score(y_test_c, y_pred_prob_c)\n","\n","print(f\"분류 성능: Acc={accuracy:.3f}, Prec={precision:.3f}, Rec={recall:.3f}, F1={f1:.3f}, AUC={auc:.3f}\")\n","\n","fig = plt.figure(figsize=(15, 5))\n","\n","plt.subplot(1, 3, 1)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n","            xticklabels=['Pred 0', 'Pred 1'],\n","            yticklabels=['True 0', 'True 1'])\n","plt.title('Confusion Matrix')\n","\n","plt.subplot(1, 3, 2)\n","# acc(정확도), precision(정밀도), recall(재현율), ...\n","metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n","values = [accuracy, precision, recall, f1, auc]\n","plt.barh(metrics, values, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6'])\n","plt.xlim(0, 1.0)\n","plt.title('Metrics')\n","plt.grid(axis='x', alpha=0.3)\n","\n","plt.subplot(1, 3, 3)\n","fpr, tpr, _ = roc_curve(y_test_c, y_pred_prob_c)\n","plt.plot(fpr, tpr, linewidth=3, label=f'AUC={auc:.3f}')\n","plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n","plt.xlabel('FPR') # false positive rate\n","plt.ylabel('TPR') # true positive rate\n","plt.title('ROC Curve')\n","plt.legend()\n","plt.grid(alpha=0.3)\n","\n","plt.tight_layout()\n","plt.savefig('result_classification.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","print(\"저장: result_classification.png\")\n","\n","# 회귀 평가\n","model_reg.eval()\n","X_test_r_t = torch.FloatTensor(X_test_r_scaled)\n","\n","with torch.no_grad():\n","    y_pred_reg = model_reg(X_test_r_t).numpy().flatten()\n","\n","mae = mean_absolute_error(y_test_r, y_pred_reg)\n","mse = mean_squared_error(y_test_r, y_pred_reg)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test_r, y_pred_reg)\n","\n","print(f\"회귀 성능: MAE={mae:.2f}, RMSE={rmse:.2f}, R2={r2:.3f}\")\n","\n","fig = plt.figure(figsize=(15, 5))\n","\n","plt.subplot(1, 3, 1)\n","plt.scatter(y_test_r, y_pred_reg, alpha=0.6, s=50)\n","# 각 관측치(관측된 포인트)에서 예측치를 뺀 값 >> 잔차\n","plt.plot([y_test_r.min(), y_test_r.max()],\n","         [y_test_r.min(), y_test_r.max()], 'r--', linewidth=3)\n","plt.xlabel('True')\n","plt.ylabel('Predicted')\n","plt.title('Prediction vs True')\n","plt.grid(alpha=0.3)\n","\n","plt.subplot(1, 3, 2)\n","residuals = y_test_r - y_pred_reg\n","plt.scatter(y_pred_reg, residuals, alpha=0.6, s=50)\n","plt.axhline(y=0, color='r', linestyle='--', linewidth=3)\n","plt.xlabel('Predicted')\n","plt.ylabel('Residuals')\n","plt.title('Residual Plot')\n","plt.grid(alpha=0.3)\n","\n","plt.subplot(1, 3, 3)\n","plt.hist(residuals, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n","plt.axvline(x=0, color='red', linestyle='--', linewidth=3)\n","plt.xlabel('Residuals')\n","plt.ylabel('Frequency')\n","plt.title('Distribution')\n","plt.grid(axis='y', alpha=0.3)\n","\n","plt.tight_layout()\n","plt.savefig('result_regression.png', dpi=150, bbox_inches='tight')\n","plt.close()\n","print(\"저장: result_regression.png\")\n","\n","\n","# =====================================================================\n","# Part 6: ML 파이프라인\n","# =====================================================================\n","print(\"\\n[Part 6] ML 파이프라인 실행\")\n","\n","class MLPipeline:\n","    def __init__(self):\n","        self.model = None\n","        self.scaler = None\n","        self.best_score = 0\n","        self.baseline_score = 0\n","\n","    def run(self, X, y):\n","        print(\"\\nSTEP 1: 문제 정의\")\n","        print(\"  목표: 고객 이탈 예측 (F1 > 0.80)\")\n","\n","        print(\"\\nSTEP 2: 데이터 준비\")\n","        X_train, X_temp, y_train, y_temp = train_test_split(\n","            X, y, test_size=0.3, random_state=42, stratify=y\n","        )\n","        X_val, X_test, y_val, y_test = train_test_split(\n","            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n","        )\n","\n","        self.scaler = StandardScaler()\n","        X_train = self.scaler.fit_transform(X_train)\n","        X_val = self.scaler.transform(X_val)\n","        X_test = self.scaler.transform(X_test)\n","\n","        print(f\"  Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n","\n","        print(\"\\nSTEP 3: 베이스라인\")\n","        majority_class = np.bincount(y_train).argmax()\n","        baseline_pred = np.full(len(y_test), majority_class)\n","        self.baseline_score = f1_score(y_test, baseline_pred, zero_division=0)\n","        print(f\"  베이스라인 F1: {self.baseline_score:.4f}\")\n","\n","        print(\"\\nSTEP 4: 모델 학습\")\n","        self.model = BinaryClassifier(input_dim=X.shape[1])\n","        criterion = nn.BCELoss()\n","        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n","\n","        X_train_t = torch.FloatTensor(X_train)\n","        y_train_t = torch.FloatTensor(y_train).unsqueeze(1)\n","        X_val_t = torch.FloatTensor(X_val)\n","        y_val_t = torch.FloatTensor(y_val).unsqueeze(1)\n","\n","        best_val_loss = float('inf')\n","        patience_counter = 0\n","\n","        for epoch in range(50):\n","            self.model.train()\n","            optimizer.zero_grad()\n","            outputs = self.model(X_train_t)\n","            loss = criterion(outputs, y_train_t)\n","            loss.backward()\n","            optimizer.step()\n","\n","            self.model.eval()\n","            with torch.no_grad():\n","                val_outputs = self.model(X_val_t)\n","                val_loss = criterion(val_outputs, y_val_t)\n","\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                best_model_state = self.model.state_dict()\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            if patience_counter >= 10:\n","                break\n","\n","        self.model.load_state_dict(best_model_state)\n","        print(\"  학습 완료\")\n","\n","        print(\"\\nSTEP 5: 최종 평가\")\n","        self.model.eval()\n","        X_test_t = torch.FloatTensor(X_test)\n","\n","        with torch.no_grad():\n","            y_pred_prob = self.model(X_test_t).numpy().flatten()\n","            y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","        test_f1 = f1_score(y_test, y_pred, zero_division=0)\n","        print(f\"  테스트 F1: {test_f1:.4f}\")\n","        print(f\"  베이스라인 대비: {test_f1 - self.baseline_score:+.4f}\")\n","\n","        if test_f1 > 0.80:\n","            print(\"  성공! 목표 달성\")\n","        else:\n","            print(\"  목표 미달, 추가 개선 필요\")\n","\n","X_proj, y_proj = make_classification(\n","    n_samples=1000, n_features=20, n_informative=15,\n","    weights=[0.65, 0.35], random_state=42\n",")\n","\n","pipeline = MLPipeline()\n","pipeline.run(X_proj, y_proj)\n","\n","\n","# =====================================================================\n","# 최종 요약\n","# =====================================================================\n","print(\"\\n\" + \"=\" * 70)\n","print(\"전체 실습 완료\")\n","print(\"=\" * 70)\n","print(\"\\n생성된 파일:\")\n","print(\"  1. result_clustering.png     - 군집화 결과\")\n","print(\"  2. result_bias_variance.png  - 편향-분산 트레이드오프\")\n","print(\"  3. result_classification.png - 분류 평가\")\n","print(\"  4. result_regression.png     - 회귀 평가\")\n","print(\"\\n모든 실습이 정상적으로 완료되었습니다.\")\n","print(\"=\" * 70)"]},{"cell_type":"code","source":["# 똑같이 쳐보기\n","class BinaryClassifier(nn.Module):\n","  def __init__(self, input_dim):\n","    self.layer1 = nn.Linear(input_dim, 64)\n","    self.layer2 = nn.Linear(64, 32)\n","    self.layer3 = nn.LInear(32, 1)\n","    self.relu = nn.ReLU()\n","    self.dropout = nn.Dropout(0.3)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    x = self.relu(self.layer1(x))\n","    x = self.dropout(x)\n","    x = self.relu(self.layer2(x))\n","    x = self.dropout(x)\n","    x = self.sigmoid(self.layer3(x))\n","    return x\n","\n","class Regressor(nn.Module):\n","  def __init__(self, input_dim):\n","    super(Regressor, self).__init__()\n","    self.network = nn.Sequential(\n","        nn.Linear(input_dim, 64),\n","        nn.ReLU(),\n","        nn.Linear(64, 32),\n","        nn.ReLU(),\n","        nn.Linear(32, 1)\n","    )\n"],"metadata":{"id":"_AG04_3TzGhQ"},"execution_count":null,"outputs":[]}]}