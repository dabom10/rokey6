{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ YOLO11 ê³ ê¸‰ ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ ì™„ë²½ ê°€ì´ë“œ\n",
    "\n",
    "## ğŸ“š ì´ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš°ëŠ” ë‚´ìš©\n",
    "1. **YOLO11 ê¸°ë³¸ ì´í•´**: ëª¨ë¸ êµ¬ì¡°ì™€ ë™ì‘ ì›ë¦¬\n",
    "2. **ê³ ê¸‰ ê²€ì¶œ ê¸°ë²•**: ì•™ìƒë¸”, ì„¸ê·¸ë©˜í…Œì´ì…˜\n",
    "3. **ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œ**: ì‹¤ë¬´ ì‘ìš© ì‚¬ë¡€\n",
    "4. **ì„±ëŠ¥ ìµœì í™”**: ì†ë„ì™€ ì •í™•ë„ ê°œì„ \n",
    "5. **ì‹¤ì „ í”„ë¡œì íŠ¸**: ì™„ì„±ëœ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "**ì‘ì„±ì**: aebonlee  \n",
    "**ë‚ ì§œ**: 2024.11.21  \n",
    "**GitHub**: [YOLO11_study](https://github.com/aebonlee/YOLO11_study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Part 1: í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "ë¨¼ì € í•„ìš”í•œ ëª¨ë“  íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "# GPU ì§€ì›ì„ ì›í•˜ë©´ pytorch ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ CUDA ë²„ì „ í™•ì¸ í›„ ì„¤ì¹˜\n",
    "\n",
    "!pip install ultralytics>=8.3.0  # YOLO11 ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "!pip install opencv-python>=4.8.0  # ì»´í“¨í„° ë¹„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "!pip install matplotlib>=3.6.0  # ì‹œê°í™”\n",
    "!pip install numpy>=1.24.0  # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "!pip install pandas>=2.0.0  # ë°ì´í„° ë¶„ì„\n",
    "!pip install scikit-learn>=1.3.0  # ë¨¸ì‹ ëŸ¬ë‹ ë„êµ¬\n",
    "!pip install scipy>=1.10.0  # ê³¼í•™ ê³„ì‚°\n",
    "!pip install seaborn>=0.12.0  # ê³ ê¸‰ ì‹œê°í™”\n",
    "!pip install tqdm>=4.65.0  # ì§„í–‰ í‘œì‹œì¤„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì—­í• ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤\n",
    "\n",
    "import cv2  # OpenCV: ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì²˜ë¦¬\n",
    "import numpy as np  # NumPy: ë°°ì—´ ì—°ì‚°\n",
    "from ultralytics import YOLO  # YOLO ëª¨ë¸\n",
    "import torch  # PyTorch: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬\n",
    "import matplotlib.pyplot as plt  # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
    "from matplotlib.patches import Rectangle, Circle, Polygon  # ë„í˜• ê·¸ë¦¬ê¸°\n",
    "import matplotlib.patches as mpatches  # ë²”ë¡€ìš© íŒ¨ì¹˜\n",
    "from pathlib import Path  # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬\n",
    "import json  # JSON ë°ì´í„° ì²˜ë¦¬\n",
    "import time  # ì‹œê°„ ì¸¡ì •\n",
    "import os  # ìš´ì˜ì²´ì œ ì¸í„°í˜ì´ìŠ¤\n",
    "from typing import List, Dict, Tuple, Optional  # íƒ€ì… íŒíŒ…\n",
    "import pandas as pd  # ë°ì´í„°í”„ë ˆì„\n",
    "import seaborn as sns  # ì‹œê°í™” ìŠ¤íƒ€ì¼\n",
    "from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œ\n",
    "from sklearn.cluster import DBSCAN  # í´ëŸ¬ìŠ¤í„°ë§\n",
    "from scipy.spatial import distance  # ê±°ë¦¬ ê³„ì‚°\n",
    "from collections import defaultdict  # ê¸°ë³¸ê°’ ë”•ì…”ë„ˆë¦¬\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Part 2: YOLO11 ê¸°ë³¸ ì´í•´\n",
    "\n",
    "### YOLO (You Only Look Once) ë€?\n",
    "- **ì‹¤ì‹œê°„ ê°ì²´ ê²€ì¶œ** ì•Œê³ ë¦¬ì¦˜\n",
    "- ì´ë¯¸ì§€ë¥¼ **í•œ ë²ˆë§Œ** ë³´ê³  ê°ì²´ ê²€ì¶œ\n",
    "- **ë°”ìš´ë”© ë°•ìŠ¤**ì™€ **í´ë˜ìŠ¤ í™•ë¥ **ì„ ë™ì‹œì— ì˜ˆì¸¡\n",
    "\n",
    "### YOLO11 ëª¨ë¸ ì¢…ë¥˜\n",
    "| ëª¨ë¸ | í¬ê¸° | ì†ë„ | ì •í™•ë„ | ìš©ë„ |\n",
    "|------|------|------|--------|------|\n",
    "| YOLOv11n | 3.2M | ë§¤ìš° ë¹ ë¦„ | ë³´í†µ | ì‹¤ì‹œê°„, ëª¨ë°”ì¼ |\n",
    "| YOLOv11s | 11.2M | ë¹ ë¦„ | ì¢‹ìŒ | ì¼ë°˜ ìš©ë„ |\n",
    "| YOLOv11m | 25.9M | ë³´í†µ | ë†’ìŒ | ê· í˜•ì¡íŒ ì„±ëŠ¥ |\n",
    "| YOLOv11l | 43.7M | ëŠë¦¼ | ë§¤ìš° ë†’ìŒ | ì •í™•ë„ ìš°ì„  |\n",
    "| YOLOv11x | 68.2M | ë§¤ìš° ëŠë¦¼ | ìµœê³  | ìµœê³  ì •í™•ë„ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO ëª¨ë¸ ë¡œë”© ì˜ˆì œ\n",
    "# ì²˜ìŒ ì‹¤í–‰ì‹œ ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤\n",
    "\n",
    "def load_yolo_model(model_name='yolo11n.pt'):\n",
    "    \"\"\"\n",
    "    YOLO ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        ëª¨ë¸ íŒŒì¼ëª… (yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : YOLO\n",
    "        ë¡œë“œëœ YOLO ëª¨ë¸ ê°ì²´\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # YOLO ëª¨ë¸ ìƒì„±\n",
    "        model = YOLO(model_name)\n",
    "        \n",
    "        # ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}\")\n",
    "        \n",
    "        # GPU ì‚¬ìš© ì„¤ì •\n",
    "        if torch.cuda.is_available():\n",
    "            model.to('cuda')\n",
    "            print(\"ğŸš€ GPU ëª¨ë“œë¡œ ì‹¤í–‰\")\n",
    "        else:\n",
    "            print(\"ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: nano ëª¨ë¸ ë¡œë“œ\n",
    "model_nano = load_yolo_model('yolo11n.pt')\n",
    "\n",
    "# ëª¨ë¸ì´ ê²€ì¶œí•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ í™•ì¸\n",
    "if model_nano:\n",
    "    print(f\"\\nğŸ“‹ ê²€ì¶œ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ìˆ˜: {len(model_nano.names)}\")\n",
    "    print(\"ì˜ˆì‹œ í´ë˜ìŠ¤:\")\n",
    "    for i, name in list(model_nano.names.items())[:10]:  # ì²˜ìŒ 10ê°œë§Œ\n",
    "        print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ–¼ï¸ Part 3: ê¸°ë³¸ ê°ì²´ ê²€ì¶œ\n",
    "\n",
    "### ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ ì²« ê²€ì¶œ ìˆ˜í–‰í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜\n",
    "import urllib.request\n",
    "\n",
    "def download_sample_images():\n",
    "    \"\"\"\n",
    "    í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    Ultralytics ê³µì‹ ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ìƒ˜í”Œ ì´ë¯¸ì§€ URLê³¼ ì €ì¥í•  íŒŒì¼ëª…\n",
    "    samples = [\n",
    "        (\"https://raw.githubusercontent.com/ultralytics/assets/main/bus.jpg\", \"bus.jpg\"),\n",
    "        (\"https://raw.githubusercontent.com/ultralytics/assets/main/zidane.jpg\", \"zidane.jpg\"),\n",
    "    ]\n",
    "    \n",
    "    # test_images í´ë” ìƒì„±\n",
    "    os.makedirs(\"test_images\", exist_ok=True)\n",
    "    \n",
    "    downloaded = []\n",
    "    for url, filename in samples:\n",
    "        filepath = f\"test_images/{filename}\"\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {filename}\")\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, filepath)\n",
    "                print(f\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {filename} - {e}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"âœ“ ì´ë¯¸ ì¡´ì¬: {filename}\")\n",
    "        \n",
    "        downloaded.append(filepath)\n",
    "    \n",
    "    return downloaded\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "sample_images = download_sample_images()\n",
    "\n",
    "# ì´ë¯¸ì§€ í‘œì‹œ\n",
    "if sample_images:\n",
    "    fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "    if len(sample_images) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, img_path in zip(axes, sample_images):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(img_rgb)\n",
    "        ax.set_title(Path(img_path).name)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(\"ìƒ˜í”Œ ì´ë¯¸ì§€\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_detection(model, image_path, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    ê¸°ë³¸ ê°ì²´ ê²€ì¶œì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : YOLO\n",
    "        YOLO ëª¨ë¸ ê°ì²´\n",
    "    image_path : str\n",
    "        ê²€ì¶œí•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "    conf_threshold : float\n",
    "        ì‹ ë¢°ë„ ì„ê³„ê°’ (0~1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results : list\n",
    "        ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ì´ë¯¸ì§€ ì½ê¸°\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # ê²€ì¶œ ìˆ˜í–‰\n",
    "    # verbose=False: ì¶œë ¥ ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "    # conf: ìµœì†Œ ì‹ ë¢°ë„ ì„¤ì •\n",
    "    results = model(image_path, conf=conf_threshold, verbose=False)\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # ì›ë³¸ ì´ë¯¸ì§€\n",
    "    ax1.imshow(image_rgb)\n",
    "    ax1.set_title(\"ì›ë³¸ ì´ë¯¸ì§€\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # ê²€ì¶œ ê²°ê³¼\n",
    "    ax2.imshow(image_rgb)\n",
    "    ax2.set_title(f\"ê²€ì¶œ ê²°ê³¼ (ì‹ ë¢°ë„ >= {conf_threshold})\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # ê²€ì¶œëœ ê°ì²´ ì •ë³´ ì €ì¥\n",
    "    detections = []\n",
    "    \n",
    "    # ê²°ê³¼ ì²˜ë¦¬\n",
    "    for r in results:\n",
    "        if r.boxes is not None:  # ê²€ì¶œëœ ê°ì²´ê°€ ìˆëŠ” ê²½ìš°\n",
    "            boxes = r.boxes\n",
    "            \n",
    "            for i, box in enumerate(boxes):\n",
    "                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                \n",
    "                # í´ë˜ìŠ¤ IDì™€ ì´ë¦„\n",
    "                cls_id = int(box.cls[0])\n",
    "                cls_name = model.names[cls_id]\n",
    "                \n",
    "                # ì‹ ë¢°ë„\n",
    "                confidence = float(box.conf[0])\n",
    "                \n",
    "                # ìƒ‰ìƒ ì„¤ì • (í´ë˜ìŠ¤ë³„ ë‹¤ë¥¸ ìƒ‰ìƒ)\n",
    "                np.random.seed(cls_id)  # ê°™ì€ í´ë˜ìŠ¤ëŠ” ê°™ì€ ìƒ‰ìƒ\n",
    "                color = np.random.rand(3)\n",
    "                \n",
    "                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "                rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                               linewidth=2, edgecolor=color,\n",
    "                               facecolor='none', alpha=0.8)\n",
    "                ax2.add_patch(rect)\n",
    "                \n",
    "                # ë¼ë²¨ ì¶”ê°€\n",
    "                label = f\"{cls_name} {confidence:.2f}\"\n",
    "                ax2.text(x1, y1-5, label, fontsize=10,\n",
    "                        color='white', backgroundcolor=color,\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                                facecolor=color, alpha=0.7))\n",
    "                \n",
    "                # ê²€ì¶œ ì •ë³´ ì €ì¥\n",
    "                detections.append({\n",
    "                    'class': cls_name,\n",
    "                    'confidence': confidence,\n",
    "                    'bbox': [x1, y1, x2, y2]\n",
    "                })\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ê²€ì¶œ í†µê³„ ì¶œë ¥\n",
    "    print(f\"\\nğŸ“Š ê²€ì¶œ í†µê³„:\")\n",
    "    print(f\"ì´ ê²€ì¶œ ê°ì²´ ìˆ˜: {len(detections)}\")\n",
    "    \n",
    "    if detections:\n",
    "        # í´ë˜ìŠ¤ë³„ ê°œìˆ˜\n",
    "        class_counts = {}\n",
    "        for det in detections:\n",
    "            cls = det['class']\n",
    "            class_counts[cls] = class_counts.get(cls, 0) + 1\n",
    "        \n",
    "        print(\"\\ní´ë˜ìŠ¤ë³„ ê²€ì¶œ ìˆ˜:\")\n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"  â€¢ {cls}: {count}ê°œ\")\n",
    "    \n",
    "    return detections\n",
    "\n",
    "# ê¸°ë³¸ ê²€ì¶œ í…ŒìŠ¤íŠ¸\n",
    "if sample_images and model_nano:\n",
    "    print(\"ğŸ” ê¸°ë³¸ ê°ì²´ ê²€ì¶œ ìˆ˜í–‰...\")\n",
    "    detections = basic_detection(model_nano, sample_images[0], conf_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Part 4: ê³ ê¸‰ ê²€ì¶œ ê¸°ë²• - ì•™ìƒë¸”\n",
    "\n",
    "### ì•™ìƒë¸”(Ensemble) ê¸°ë²•ì´ë€?\n",
    "- **ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê²°í•©**í•˜ì—¬ ì •í™•ë„ í–¥ìƒ\n",
    "- ê° ëª¨ë¸ì˜ ì¥ì ì„ í™œìš©\n",
    "- ì˜¤íƒì§€(False Positive) ê°ì†Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleDetector:\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ YOLO ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ì—¬ ê²€ì¶œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” í´ë˜ìŠ¤\n",
    "    \n",
    "    ì•™ìƒë¸” ì „ëµ:\n",
    "    1. ì—¬ëŸ¬ ëª¨ë¸ë¡œ ë…ë¦½ì ìœ¼ë¡œ ê²€ì¶œ\n",
    "    2. ê° ê²€ì¶œ ê²°ê³¼ì˜ ì‹ ë¢°ë„ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©\n",
    "    3. IoU ê¸°ë°˜ìœ¼ë¡œ ê°™ì€ ê°ì²´ íŒë³„\n",
    "    4. íˆ¬í‘œ(Voting) ë˜ëŠ” í‰ê· ìœ¼ë¡œ ìµœì¢… ê²°ì •\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_configs):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_configs : list\n",
    "            [(model_name, weight), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸\n",
    "            ì˜ˆ: [('yolo11n.pt', 0.3), ('yolo11s.pt', 0.3), ('yolo11m.pt', 0.4)]\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "        \n",
    "        print(\"ğŸ”§ ì•™ìƒë¸” ê²€ì¶œê¸° ì´ˆê¸°í™”...\")\n",
    "        \n",
    "        for model_name, weight in model_configs:\n",
    "            print(f\"  â€¢ {model_name} ë¡œë”© (ê°€ì¤‘ì¹˜: {weight})\")\n",
    "            model = YOLO(model_name)\n",
    "            self.models.append(model)\n",
    "            self.weights.append(weight)\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)\n",
    "        total_weight = sum(self.weights)\n",
    "        self.weights = [w / total_weight for w in self.weights]\n",
    "        \n",
    "        print(f\"âœ… {len(self.models)}ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ\")\n",
    "    \n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"\n",
    "        ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU(Intersection over Union) ê³„ì‚°\n",
    "        \n",
    "        IoU = êµì§‘í•© ì˜ì—­ / í•©ì§‘í•© ì˜ì—­\n",
    "        \"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        # êµì§‘í•© ì˜ì—­\n",
    "        intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        \n",
    "        # ê° ë°•ìŠ¤ì˜ ì˜ì—­\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        # í•©ì§‘í•© ì˜ì—­\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        # IoU ê³„ì‚°\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        \n",
    "        return iou\n",
    "    \n",
    "    def ensemble_detect(self, image_path, conf_threshold=0.4, iou_threshold=0.5):\n",
    "        \"\"\"\n",
    "        ì•™ìƒë¸” ê²€ì¶œ ìˆ˜í–‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        image_path : str\n",
    "            ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        conf_threshold : float\n",
    "            ìµœì†Œ ì‹ ë¢°ë„\n",
    "        iou_threshold : float\n",
    "            ê°™ì€ ê°ì²´ë¡œ íŒë‹¨í•  IoU ì„ê³„ê°’\n",
    "        \"\"\"\n",
    "        all_detections = []\n",
    "        \n",
    "        # ê° ëª¨ë¸ë¡œ ê²€ì¶œ ìˆ˜í–‰\n",
    "        for model, weight in zip(self.models, self.weights):\n",
    "            results = model(image_path, conf=conf_threshold, verbose=False)\n",
    "            \n",
    "            for r in results:\n",
    "                if r.boxes is not None:\n",
    "                    for box in r.boxes:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                        cls_id = int(box.cls[0])\n",
    "                        conf = float(box.conf[0])\n",
    "                        \n",
    "                        all_detections.append({\n",
    "                            'bbox': [x1, y1, x2, y2],\n",
    "                            'class': model.names[cls_id],\n",
    "                            'class_id': cls_id,\n",
    "                            'confidence': conf * weight,  # ê°€ì¤‘ì¹˜ ì ìš©\n",
    "                            'weight': weight\n",
    "                        })\n",
    "        \n",
    "        # ì•™ìƒë¸” ê²°ê³¼ í†µí•©\n",
    "        ensemble_results = self._merge_detections(all_detections, iou_threshold)\n",
    "        \n",
    "        return ensemble_results\n",
    "    \n",
    "    def _merge_detections(self, detections, iou_threshold=0.5):\n",
    "        \"\"\"\n",
    "        ì¤‘ë³µ ê²€ì¶œ ê²°ê³¼ë¥¼ í†µí•©\n",
    "        \"\"\"\n",
    "        if not detections:\n",
    "            return []\n",
    "        \n",
    "        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        merged = []\n",
    "        used = [False] * len(detections)\n",
    "        \n",
    "        for i, det1 in enumerate(detections):\n",
    "            if used[i]:\n",
    "                continue\n",
    "            \n",
    "            # ê°™ì€ ê°ì²´ë¡œ íŒë‹¨ë˜ëŠ” ê²€ì¶œë“¤ ê·¸ë£¹í™”\n",
    "            group = [det1]\n",
    "            used[i] = True\n",
    "            \n",
    "            for j, det2 in enumerate(detections[i+1:], i+1):\n",
    "                if used[j]:\n",
    "                    continue\n",
    "                \n",
    "                # ê°™ì€ í´ë˜ìŠ¤ì´ê³  IoUê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ ê°™ì€ ê°ì²´\n",
    "                if (det1['class'] == det2['class'] and \n",
    "                    self.calculate_iou(det1['bbox'], det2['bbox']) > iou_threshold):\n",
    "                    group.append(det2)\n",
    "                    used[j] = True\n",
    "            \n",
    "            # ê·¸ë£¹ì˜ í‰ê· ìœ¼ë¡œ ìµœì¢… ê²€ì¶œ ìƒì„±\n",
    "            if len(group) >= len(self.models) // 2:  # ê³¼ë°˜ìˆ˜ ì´ìƒì´ ê²€ì¶œí•œ ê²½ìš°ë§Œ\n",
    "                avg_bbox = np.mean([d['bbox'] for d in group], axis=0)\n",
    "                avg_conf = np.mean([d['confidence'] for d in group])\n",
    "                \n",
    "                merged.append({\n",
    "                    'bbox': avg_bbox.tolist(),\n",
    "                    'class': group[0]['class'],\n",
    "                    'confidence': avg_conf,\n",
    "                    'votes': len(group)  # ëª‡ ê°œ ëª¨ë¸ì´ ê²€ì¶œí–ˆëŠ”ì§€\n",
    "                })\n",
    "        \n",
    "        return merged\n",
    "\n",
    "# ì•™ìƒë¸” ê²€ì¶œê¸° ìƒì„± ë° í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ¯ ì•™ìƒë¸” ê²€ì¶œ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "# 3ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸” êµ¬ì„±\n",
    "ensemble_configs = [\n",
    "    ('yolo11n.pt', 0.2),  # Nano - ë¹ ë¥´ì§€ë§Œ ì •í™•ë„ ë‚®ìŒ\n",
    "    ('yolo11s.pt', 0.3),  # Small - ê· í˜•\n",
    "    ('yolo11m.pt', 0.5),  # Medium - ì •í™•ë„ ë†’ìŒ\n",
    "]\n",
    "\n",
    "ensemble = EnsembleDetector(ensemble_configs)\n",
    "\n",
    "if sample_images:\n",
    "    # ì•™ìƒë¸” ê²€ì¶œ ìˆ˜í–‰\n",
    "    ensemble_results = ensemble.ensemble_detect(sample_images[0])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì•™ìƒë¸” ê²€ì¶œ ê²°ê³¼:\")\n",
    "    print(f\"ê²€ì¶œëœ ê°ì²´ ìˆ˜: {len(ensemble_results)}\")\n",
    "    \n",
    "    for i, det in enumerate(ensemble_results):\n",
    "        print(f\"\\nê°ì²´ {i+1}:\")\n",
    "        print(f\"  í´ë˜ìŠ¤: {det['class']}\")\n",
    "        print(f\"  ì‹ ë¢°ë„: {det['confidence']:.3f}\")\n",
    "        print(f\"  íˆ¬í‘œ ìˆ˜: {det['votes']}/{len(ensemble.models)} ëª¨ë¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Part 5: ì„¸ê·¸ë©˜í…Œì´ì…˜ (Segmentation)\n",
    "\n",
    "### ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ë€?\n",
    "- **í”½ì…€ ë‹¨ìœ„**ë¡œ ê°ì²´ë¥¼ ë¶„ë¥˜\n",
    "- ë°”ìš´ë”© ë°•ìŠ¤ë³´ë‹¤ **ì •í™•í•œ ìœ¤ê³½ì„ ** ì œê³µ\n",
    "- ì˜ë£Œ ì˜ìƒ, ììœ¨ì£¼í–‰ ë“±ì— í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDetector:\n",
    "    \"\"\"\n",
    "    YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì •ë°€ ê°ì²´ ê²€ì¶œ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='yolo11n-seg.pt'):\n",
    "        \"\"\"\n",
    "        ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        -seg ì ‘ë¯¸ì‚¬ê°€ ë¶™ì€ ëª¨ë¸ ì‚¬ìš©\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”©: {model_name}\")\n",
    "        self.model = YOLO(model_name)\n",
    "        print(\"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "    \n",
    "    def segment_image(self, image_path, conf_threshold=0.5):\n",
    "        \"\"\"\n",
    "        ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰\n",
    "        \"\"\"\n",
    "        # ì´ë¯¸ì§€ ì½ê¸°\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w = image_rgb.shape[:2]\n",
    "        \n",
    "        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰\n",
    "        results = self.model(image_path, conf=conf_threshold, verbose=False)\n",
    "        \n",
    "        # ê²°ê³¼ ì‹œê°í™”ë¥¼ ìœ„í•œ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ìƒì„±\n",
    "        mask_image = np.zeros_like(image_rgb)\n",
    "        overlay_image = image_rgb.copy()\n",
    "        \n",
    "        # ê²€ì¶œ ì •ë³´ ì €ì¥\n",
    "        segmentation_results = []\n",
    "        \n",
    "        for r in results:\n",
    "            if r.masks is not None:  # ë§ˆìŠ¤í¬ê°€ ìˆëŠ” ê²½ìš°\n",
    "                masks = r.masks.data.cpu().numpy()\n",
    "                boxes = r.boxes\n",
    "                \n",
    "                for i, (mask, box) in enumerate(zip(masks, boxes)):\n",
    "                    # í´ë˜ìŠ¤ ì •ë³´\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    cls_name = self.model.names[cls_id]\n",
    "                    confidence = float(box.conf[0])\n",
    "                    \n",
    "                    # ìƒ‰ìƒ ìƒì„± (í´ë˜ìŠ¤ë³„ ê³ ìœ  ìƒ‰ìƒ)\n",
    "                    np.random.seed(cls_id)\n",
    "                    color = (np.random.rand(3) * 255).astype(int)\n",
    "                    \n",
    "                    # ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "                    mask_resized = cv2.resize(mask, (w, h))\n",
    "                    \n",
    "                    # ë§ˆìŠ¤í¬ ì ìš©\n",
    "                    mask_bool = mask_resized > 0.5\n",
    "                    mask_image[mask_bool] = color\n",
    "                    \n",
    "                    # ì˜¤ë²„ë ˆì´ ìƒì„± (ë°˜íˆ¬ëª…)\n",
    "                    alpha = 0.4\n",
    "                    overlay_image[mask_bool] = (\n",
    "                        overlay_image[mask_bool] * (1 - alpha) + \n",
    "                        color * alpha\n",
    "                    ).astype(np.uint8)\n",
    "                    \n",
    "                    # ë§ˆìŠ¤í¬ ë©´ì  ê³„ì‚°\n",
    "                    area = np.sum(mask_bool)\n",
    "                    area_percentage = (area / (w * h)) * 100\n",
    "                    \n",
    "                    segmentation_results.append({\n",
    "                        'class': cls_name,\n",
    "                        'confidence': confidence,\n",
    "                        'area_pixels': area,\n",
    "                        'area_percentage': area_percentage\n",
    "                    })\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        self._visualize_segmentation(image_rgb, mask_image, overlay_image, \n",
    "                                    segmentation_results)\n",
    "        \n",
    "        return segmentation_results\n",
    "    \n",
    "    def _visualize_segmentation(self, original, mask, overlay, results):\n",
    "        \"\"\"\n",
    "        ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™”\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # ì›ë³¸ ì´ë¯¸ì§€\n",
    "        axes[0].imshow(original)\n",
    "        axes[0].set_title(\"ì›ë³¸ ì´ë¯¸ì§€\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬\n",
    "        axes[1].imshow(mask)\n",
    "        axes[1].set_title(\"ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€\n",
    "        axes[2].imshow(overlay)\n",
    "        axes[2].set_title(\"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜¤ë²„ë ˆì´\")\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        # ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€\n",
    "        info_text = \"ê²€ì¶œëœ ê°ì²´:\\n\"\n",
    "        for r in results:\n",
    "            info_text += f\"â€¢ {r['class']}: {r['area_percentage']:.1f}% of image\\n\"\n",
    "        \n",
    "        fig.text(0.5, 0.02, info_text, ha='center', fontsize=10,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", \n",
    "                         facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²€ì¶œ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "seg_detector = SegmentationDetector('yolo11n-seg.pt')\n",
    "\n",
    "if sample_images:\n",
    "    seg_results = seg_detector.segment_image(sample_images[0])\n",
    "    \n",
    "    print(\"\\nğŸ“Š ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼:\")\n",
    "    for i, result in enumerate(seg_results):\n",
    "        print(f\"\\nê°ì²´ {i+1}:\")\n",
    "        print(f\"  í´ë˜ìŠ¤: {result['class']}\")\n",
    "        print(f\"  ì‹ ë¢°ë„: {result['confidence']:.3f}\")\n",
    "        print(f\"  ì˜ì—­: {result['area_percentage']:.2f}% of image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¢ Part 6: ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œ\n",
    "\n",
    "### ì‹¤ë¬´ ì‘ìš© ì‚¬ë¡€\n",
    "íŠ¹ì • ë¶„ì•¼ì— ìµœì í™”ëœ ê²€ì¶œ ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainSpecificDetector:\n",
    "    \"\"\"\n",
    "    ë„ë©”ì¸ë³„ íŠ¹í™” ê²€ì¶œ ì‹œìŠ¤í…œ\n",
    "    ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ì¶° ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ\n",
    "    \"\"\"\n",
    "    \n",
    "    # ë„ë©”ì¸ë³„ ì¤‘ìš” í´ë˜ìŠ¤ ì •ì˜\n",
    "    DOMAINS = {\n",
    "        'traffic': {\n",
    "            'classes': ['person', 'car', 'bus', 'truck', 'bicycle', \n",
    "                       'motorcycle', 'traffic light', 'stop sign'],\n",
    "            'alerts': {\n",
    "                'jaywalking': 'Person detected in vehicle lane',\n",
    "                'congestion': 'High vehicle density detected',\n",
    "                'accident_risk': 'Close proximity between vehicles'\n",
    "            }\n",
    "        },\n",
    "        'retail': {\n",
    "            'classes': ['person', 'handbag', 'backpack', 'suitcase', \n",
    "                       'bottle', 'cup', 'cell phone'],\n",
    "            'alerts': {\n",
    "                'crowding': 'Store crowding detected',\n",
    "                'unattended_bag': 'Unattended bag detected',\n",
    "                'queue_forming': 'Queue formation detected'\n",
    "            }\n",
    "        },\n",
    "        'security': {\n",
    "            'classes': ['person', 'knife', 'backpack', 'suitcase'],\n",
    "            'alerts': {\n",
    "                'weapon': 'Potential weapon detected',\n",
    "                'intrusion': 'Unauthorized person detected',\n",
    "                'suspicious_item': 'Suspicious item detected'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, domain='general', model_name='yolo11m.pt'):\n",
    "        \"\"\"\n",
    "        ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œê¸° ì´ˆê¸°í™”\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        domain : str\n",
    "            'traffic', 'retail', 'security', 'general'\n",
    "        \"\"\"\n",
    "        self.domain = domain\n",
    "        self.model = YOLO(model_name)\n",
    "        \n",
    "        # ë„ë©”ì¸ë³„ íƒ€ê²Ÿ í´ë˜ìŠ¤ ì„¤ì •\n",
    "        if domain in self.DOMAINS:\n",
    "            self.target_classes = self.DOMAINS[domain]['classes']\n",
    "            self.alerts_config = self.DOMAINS[domain]['alerts']\n",
    "        else:\n",
    "            self.target_classes = None\n",
    "            self.alerts_config = {}\n",
    "        \n",
    "        print(f\"ğŸ¢ ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œê¸° ì´ˆê¸°í™”: {domain}\")\n",
    "        if self.target_classes:\n",
    "            print(f\"   ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤: {', '.join(self.target_classes[:5])}...\")\n",
    "    \n",
    "    def detect_and_analyze(self, image_path, conf_threshold=0.45):\n",
    "        \"\"\"\n",
    "        ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œ ë° ë¶„ì„\n",
    "        \"\"\"\n",
    "        # ê¸°ë³¸ ê²€ì¶œ\n",
    "        results = self.model(image_path, conf=conf_threshold, verbose=False)\n",
    "        \n",
    "        # ë„ë©”ì¸ í•„í„°ë§\n",
    "        filtered_detections = []\n",
    "        all_detections = []\n",
    "        \n",
    "        for r in results:\n",
    "            if r.boxes is not None:\n",
    "                for box in r.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    cls_name = self.model.names[cls_id]\n",
    "                    conf = float(box.conf[0])\n",
    "                    \n",
    "                    detection = {\n",
    "                        'bbox': [x1, y1, x2, y2],\n",
    "                        'class': cls_name,\n",
    "                        'confidence': conf,\n",
    "                        'center': [(x1+x2)/2, (y1+y2)/2],\n",
    "                        'area': (x2-x1) * (y2-y1)\n",
    "                    }\n",
    "                    \n",
    "                    all_detections.append(detection)\n",
    "                    \n",
    "                    # ë„ë©”ì¸ í•„í„°ë§\n",
    "                    if self.target_classes is None or cls_name in self.target_classes:\n",
    "                        filtered_detections.append(detection)\n",
    "        \n",
    "        # ë„ë©”ì¸ë³„ ë¶„ì„\n",
    "        analysis = self._domain_analysis(filtered_detections)\n",
    "        \n",
    "        # ì•ŒëŒ ì²´í¬\n",
    "        alerts = self._check_alerts(filtered_detections, analysis)\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        self._visualize_domain_detection(image_path, filtered_detections, \n",
    "                                        analysis, alerts)\n",
    "        \n",
    "        return {\n",
    "            'detections': filtered_detections,\n",
    "            'analysis': analysis,\n",
    "            'alerts': alerts\n",
    "        }\n",
    "    \n",
    "    def _domain_analysis(self, detections):\n",
    "        \"\"\"\n",
    "        ë„ë©”ì¸ë³„ ë¶„ì„ ìˆ˜í–‰\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            'total_objects': len(detections),\n",
    "            'class_distribution': {},\n",
    "            'density': None,\n",
    "            'patterns': []\n",
    "        }\n",
    "        \n",
    "        # í´ë˜ìŠ¤ë³„ ë¶„í¬\n",
    "        for det in detections:\n",
    "            cls = det['class']\n",
    "            analysis['class_distribution'][cls] = \\\n",
    "                analysis['class_distribution'].get(cls, 0) + 1\n",
    "        \n",
    "        # ë„ë©”ì¸ë³„ íŠ¹ìˆ˜ ë¶„ì„\n",
    "        if self.domain == 'traffic':\n",
    "            # êµí†µ ë¶„ì„: ì°¨ëŸ‰ê³¼ ë³´í–‰ì ë¶„ë¦¬\n",
    "            vehicles = [d for d in detections \n",
    "                       if d['class'] in ['car', 'bus', 'truck']]\n",
    "            pedestrians = [d for d in detections \n",
    "                          if d['class'] == 'person']\n",
    "            \n",
    "            analysis['vehicles'] = len(vehicles)\n",
    "            analysis['pedestrians'] = len(pedestrians)\n",
    "            \n",
    "            # ìœ„í—˜ë„ ê³„ì‚°\n",
    "            if vehicles and pedestrians:\n",
    "                min_distance = float('inf')\n",
    "                for v in vehicles:\n",
    "                    for p in pedestrians:\n",
    "                        dist = distance.euclidean(v['center'], p['center'])\n",
    "                        min_distance = min(min_distance, dist)\n",
    "                \n",
    "                analysis['min_vehicle_pedestrian_distance'] = min_distance\n",
    "                analysis['risk_level'] = 'high' if min_distance < 100 else 'low'\n",
    "        \n",
    "        elif self.domain == 'retail':\n",
    "            # ë¦¬í…Œì¼ ë¶„ì„: ê³ ê° ë°€ë„\n",
    "            persons = [d for d in detections if d['class'] == 'person']\n",
    "            analysis['customer_count'] = len(persons)\n",
    "            \n",
    "            # ë°€ì§‘ë„ ê³„ì‚° (DBSCAN í´ëŸ¬ìŠ¤í„°ë§)\n",
    "            if len(persons) > 2:\n",
    "                centers = np.array([p['center'] for p in persons])\n",
    "                clustering = DBSCAN(eps=150, min_samples=2).fit(centers)\n",
    "                n_clusters = len(set(clustering.labels_)) - (1 if -1 in clustering.labels_ else 0)\n",
    "                analysis['crowd_clusters'] = n_clusters\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def _check_alerts(self, detections, analysis):\n",
    "        \"\"\"\n",
    "        ì•ŒëŒ ì¡°ê±´ ì²´í¬\n",
    "        \"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        if self.domain == 'traffic':\n",
    "            # êµí†µ ì•ŒëŒ\n",
    "            if analysis.get('risk_level') == 'high':\n",
    "                alerts.append({\n",
    "                    'type': 'accident_risk',\n",
    "                    'severity': 'high',\n",
    "                    'message': self.alerts_config.get('accident_risk', '')\n",
    "                })\n",
    "            \n",
    "            if analysis.get('vehicles', 0) > 5:\n",
    "                alerts.append({\n",
    "                    'type': 'congestion',\n",
    "                    'severity': 'medium',\n",
    "                    'message': self.alerts_config.get('congestion', '')\n",
    "                })\n",
    "        \n",
    "        elif self.domain == 'retail':\n",
    "            # ë¦¬í…Œì¼ ì•ŒëŒ\n",
    "            if analysis.get('customer_count', 0) > 10:\n",
    "                alerts.append({\n",
    "                    'type': 'crowding',\n",
    "                    'severity': 'medium',\n",
    "                    'message': self.alerts_config.get('crowding', '')\n",
    "                })\n",
    "        \n",
    "        elif self.domain == 'security':\n",
    "            # ë³´ì•ˆ ì•ŒëŒ\n",
    "            dangerous_items = ['knife', 'gun']\n",
    "            for det in detections:\n",
    "                if det['class'] in dangerous_items:\n",
    "                    alerts.append({\n",
    "                        'type': 'weapon',\n",
    "                        'severity': 'critical',\n",
    "                        'message': f\"Weapon detected: {det['class']}\"\n",
    "                    })\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def _visualize_domain_detection(self, image_path, detections, analysis, alerts):\n",
    "        \"\"\"\n",
    "        ë„ë©”ì¸ íŠ¹í™” ì‹œê°í™”\n",
    "        \"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        \n",
    "        # ê²€ì¶œ ê²°ê³¼ í‘œì‹œ\n",
    "        ax1.imshow(image_rgb)\n",
    "        ax1.set_title(f\"{self.domain.upper()} Domain Detection\")\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # ë„ë©”ì¸ë³„ ìƒ‰ìƒ ì„¤ì •\n",
    "        color_map = {\n",
    "            'person': 'blue',\n",
    "            'car': 'green',\n",
    "            'bus': 'orange',\n",
    "            'truck': 'brown',\n",
    "            'knife': 'red',\n",
    "            'backpack': 'purple'\n",
    "        }\n",
    "        \n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            color = color_map.get(det['class'], 'gray')\n",
    "            \n",
    "            # ì•ŒëŒì´ ìˆëŠ” ê°ì²´ëŠ” ë¹¨ê°„ìƒ‰ í…Œë‘ë¦¬\n",
    "            if any(a['severity'] == 'critical' for a in alerts):\n",
    "                if det['class'] in ['knife', 'gun']:\n",
    "                    color = 'red'\n",
    "            \n",
    "            rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                           linewidth=2, edgecolor=color,\n",
    "                           facecolor='none', alpha=0.8)\n",
    "            ax1.add_patch(rect)\n",
    "            \n",
    "            label = f\"{det['class']} {det['confidence']:.2f}\"\n",
    "            ax1.text(x1, y1-5, label, fontsize=9,\n",
    "                    color='white', backgroundcolor=color,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                            facecolor=color, alpha=0.7))\n",
    "        \n",
    "        # ë¶„ì„ ì •ë³´ í‘œì‹œ\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        info_text = f\"ğŸ¢ Domain: {self.domain.upper()}\\n\\n\"\n",
    "        info_text += f\"ğŸ“Š Analysis:\\n\"\n",
    "        info_text += f\"â€¢ Total objects: {analysis['total_objects']}\\n\"\n",
    "        \n",
    "        if self.domain == 'traffic':\n",
    "            info_text += f\"â€¢ Vehicles: {analysis.get('vehicles', 0)}\\n\"\n",
    "            info_text += f\"â€¢ Pedestrians: {analysis.get('pedestrians', 0)}\\n\"\n",
    "            info_text += f\"â€¢ Risk level: {analysis.get('risk_level', 'unknown')}\\n\"\n",
    "        elif self.domain == 'retail':\n",
    "            info_text += f\"â€¢ Customers: {analysis.get('customer_count', 0)}\\n\"\n",
    "            info_text += f\"â€¢ Crowd clusters: {analysis.get('crowd_clusters', 0)}\\n\"\n",
    "        \n",
    "        info_text += \"\\nğŸ“‹ Class Distribution:\\n\"\n",
    "        for cls, count in analysis['class_distribution'].items():\n",
    "            info_text += f\"â€¢ {cls}: {count}\\n\"\n",
    "        \n",
    "        if alerts:\n",
    "            info_text += \"\\nâš ï¸ ALERTS:\\n\"\n",
    "            for alert in alerts:\n",
    "                severity_emoji = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', \n",
    "                                'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}\n",
    "                emoji = severity_emoji.get(alert['severity'], 'âšª')\n",
    "                info_text += f\"{emoji} {alert['message']}\\n\"\n",
    "        \n",
    "        ax2.text(0.1, 0.9, info_text, transform=ax2.transAxes,\n",
    "                fontsize=11, verticalalignment='top',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\",\n",
    "                        facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ¢ ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "# êµí†µ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸\n",
    "traffic_detector = DomainSpecificDetector(domain='traffic')\n",
    "\n",
    "if sample_images:\n",
    "    print(\"\\nğŸš— êµí†µ ë„ë©”ì¸ ë¶„ì„:\")\n",
    "    traffic_results = traffic_detector.detect_and_analyze(sample_images[0])\n",
    "    \n",
    "    print(f\"ê²€ì¶œëœ ê´€ë ¨ ê°ì²´: {len(traffic_results['detections'])}\")\n",
    "    if traffic_results['alerts']:\n",
    "        print(f\"ìƒì„±ëœ ì•ŒëŒ: {len(traffic_results['alerts'])}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Part 7: ì„±ëŠ¥ ë¹„êµ ë° ìµœì í™”\n",
    "\n",
    "### ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    \"\"\"\n",
    "    YOLO ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "    \n",
    "    def benchmark_models(self, image_path, models_list):\n",
    "        \"\"\"\n",
    "        ì—¬ëŸ¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        models_list : list\n",
    "            [(model_name, model_path), ...]\n",
    "        \"\"\"\n",
    "        print(\"ğŸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...\\n\")\n",
    "        \n",
    "        for model_name, model_path in tqdm(models_list, desc=\"ëª¨ë¸ í…ŒìŠ¤íŠ¸\"):\n",
    "            try:\n",
    "                # ëª¨ë¸ ë¡œë“œ\n",
    "                model = YOLO(model_path)\n",
    "                \n",
    "                # ì›Œë°ì—… (ì²« ì‹¤í–‰ì€ ëŠë¦¼)\n",
    "                _ = model(image_path, verbose=False)\n",
    "                \n",
    "                # ì„±ëŠ¥ ì¸¡ì • (5íšŒ í‰ê· )\n",
    "                times = []\n",
    "                detections_counts = []\n",
    "                \n",
    "                for _ in range(5):\n",
    "                    start_time = time.time()\n",
    "                    results = model(image_path, verbose=False)\n",
    "                    elapsed = time.time() - start_time\n",
    "                    times.append(elapsed)\n",
    "                    \n",
    "                    # ê²€ì¶œ ìˆ˜ ê³„ì‚°\n",
    "                    n_detections = 0\n",
    "                    for r in results:\n",
    "                        if r.boxes is not None:\n",
    "                            n_detections += len(r.boxes)\n",
    "                    detections_counts.append(n_detections)\n",
    "                \n",
    "                # í†µê³„ ê³„ì‚°\n",
    "                avg_time = np.mean(times)\n",
    "                std_time = np.std(times)\n",
    "                fps = 1 / avg_time\n",
    "                avg_detections = np.mean(detections_counts)\n",
    "                \n",
    "                # ëª¨ë¸ í¬ê¸° ì •ë³´\n",
    "                model_size = self._get_model_size(model_name)\n",
    "                \n",
    "                self.results.append({\n",
    "                    'model': model_name,\n",
    "                    'avg_time': avg_time,\n",
    "                    'std_time': std_time,\n",
    "                    'fps': fps,\n",
    "                    'detections': avg_detections,\n",
    "                    'model_size': model_size\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {model_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return pd.DataFrame(self.results)\n",
    "    \n",
    "    def _get_model_size(self, model_name):\n",
    "        \"\"\"ëª¨ë¸ í¬ê¸° ì •ë³´ ë°˜í™˜\"\"\"\n",
    "        sizes = {\n",
    "            'YOLOv11n': '3.2M',\n",
    "            'YOLOv11s': '11.2M',\n",
    "            'YOLOv11m': '25.9M',\n",
    "            'YOLOv11l': '43.7M',\n",
    "            'YOLOv11x': '68.2M'\n",
    "        }\n",
    "        return sizes.get(model_name, 'Unknown')\n",
    "    \n",
    "    def visualize_results(self, df):\n",
    "        \"\"\"\n",
    "        ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # 1. FPS ë¹„êµ\n",
    "        axes[0, 0].bar(df['model'], df['fps'], color='skyblue')\n",
    "        axes[0, 0].set_xlabel('Model')\n",
    "        axes[0, 0].set_ylabel('FPS')\n",
    "        axes[0, 0].set_title('Frames Per Second (Higher is Better)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # FPS ê°’ í‘œì‹œ\n",
    "        for i, v in enumerate(df['fps']):\n",
    "            axes[0, 0].text(i, v + 1, f'{v:.1f}', ha='center')\n",
    "        \n",
    "        # 2. ì¶”ë¡  ì‹œê°„ ë¹„êµ\n",
    "        axes[0, 1].bar(df['model'], df['avg_time'] * 1000, color='lightcoral')\n",
    "        axes[0, 1].set_xlabel('Model')\n",
    "        axes[0, 1].set_ylabel('Time (ms)')\n",
    "        axes[0, 1].set_title('Average Inference Time (Lower is Better)')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 3. ê²€ì¶œ ìˆ˜ ë¹„êµ\n",
    "        axes[1, 0].bar(df['model'], df['detections'], color='lightgreen')\n",
    "        axes[1, 0].set_xlabel('Model')\n",
    "        axes[1, 0].set_ylabel('Number of Detections')\n",
    "        axes[1, 0].set_title('Average Detection Count')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 4. íš¨ìœ¨ì„± ë§¤íŠ¸ë¦­ìŠ¤ (ì†ë„ vs ê²€ì¶œ)\n",
    "        axes[1, 1].scatter(df['fps'], df['detections'], s=200, alpha=0.6)\n",
    "        \n",
    "        # ëª¨ë¸ëª… ë¼ë²¨ ì¶”ê°€\n",
    "        for idx, row in df.iterrows():\n",
    "            axes[1, 1].annotate(row['model'], \n",
    "                              (row['fps'], row['detections']),\n",
    "                              xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        axes[1, 1].set_xlabel('FPS')\n",
    "        axes[1, 1].set_ylabel('Detection Count')\n",
    "        axes[1, 1].set_title('Speed vs Detection Trade-off')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('YOLO Model Performance Comparison', fontsize=16, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # ìš”ì•½ í…Œì´ë¸” ì¶œë ¥\n",
    "        print(\"\\nğŸ“‹ ì„±ëŠ¥ ë¹„êµ ìš”ì•½:\")\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # ì¶”ì²œ ì‚¬í•­\n",
    "        print(\"\\nğŸ’¡ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ:\")\n",
    "        fastest_model = df.loc[df['fps'].idxmax(), 'model']\n",
    "        most_detections = df.loc[df['detections'].idxmax(), 'model']\n",
    "        \n",
    "        print(f\"â€¢ ì‹¤ì‹œê°„ ì²˜ë¦¬: {fastest_model} (ìµœê³  FPS)\")\n",
    "        print(f\"â€¢ ìµœê³  ì •í™•ë„: {most_detections} (ìµœë‹¤ ê²€ì¶œ)\")\n",
    "        \n",
    "        # ê· í˜•ì¡íŒ ëª¨ë¸ ì°¾ê¸° (FPSì™€ ê²€ì¶œ ìˆ˜ì˜ ì¡°í™”í‰ê· )\n",
    "        df['efficiency'] = 2 * (df['fps'] / df['fps'].max()) * \\\n",
    "                          (df['detections'] / df['detections'].max()) / \\\n",
    "                          ((df['fps'] / df['fps'].max()) + \\\n",
    "                           (df['detections'] / df['detections'].max()))\n",
    "        \n",
    "        balanced_model = df.loc[df['efficiency'].idxmax(), 'model']\n",
    "        print(f\"â€¢ ê· í˜•ì¡íŒ ì„ íƒ: {balanced_model}\")\n",
    "\n",
    "# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë²¤ì¹˜ë§ˆí¬\")\n",
    "\n",
    "benchmark = PerformanceBenchmark()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ëª©ë¡\n",
    "test_models = [\n",
    "    ('YOLOv11n', 'yolo11n.pt'),\n",
    "    ('YOLOv11s', 'yolo11s.pt'),\n",
    "    ('YOLOv11m', 'yolo11m.pt'),\n",
    "]\n",
    "\n",
    "if sample_images:\n",
    "    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\n",
    "    results_df = benchmark.benchmark_models(sample_images[0], test_models)\n",
    "    \n",
    "    # ê²°ê³¼ ì‹œê°í™”\n",
    "    if not results_df.empty:\n",
    "        benchmark.visualize_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Part 8: ì‹¤ì „ í”„ë¡œì íŠ¸ - ì™„ì„±ëœ ì‹œìŠ¤í…œ\n",
    "\n",
    "### ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ëª¨ë“  ê¸°ìˆ ì„ í†µí•©í•œ ì‹¤ì „ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedDetectionSystem:\n",
    "    \"\"\"\n",
    "    í†µí•© ê°ì²´ ê²€ì¶œ ì‹œìŠ¤í…œ\n",
    "    ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ ê²°í•©\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"ğŸš€ í†µí•© ê²€ì¶œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n",
    "        \n",
    "        # ê¸°ë³¸ ê²€ì¶œê¸°\n",
    "        self.base_model = YOLO('yolo11m.pt')\n",
    "        \n",
    "        # ì•™ìƒë¸” ê²€ì¶œê¸°\n",
    "        self.ensemble = EnsembleDetector([\n",
    "            ('yolo11n.pt', 0.2),\n",
    "            ('yolo11s.pt', 0.3),\n",
    "            ('yolo11m.pt', 0.5)\n",
    "        ])\n",
    "        \n",
    "        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²€ì¶œê¸°\n",
    "        self.segmentation = SegmentationDetector('yolo11n-seg.pt')\n",
    "        \n",
    "        # ê²€ì¶œ ê¸°ë¡\n",
    "        self.detection_history = []\n",
    "        \n",
    "        print(\"âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "    \n",
    "    def detect(self, image_path, mode='auto', domain=None, \n",
    "              save_results=True):\n",
    "        \"\"\"\n",
    "        í†µí•© ê²€ì¶œ ìˆ˜í–‰\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        mode : str\n",
    "            'fast', 'balanced', 'accurate', 'segmentation', 'auto'\n",
    "        domain : str\n",
    "            íŠ¹ì • ë„ë©”ì¸ ì§€ì • (ì„ íƒì‚¬í•­)\n",
    "        save_results : bool\n",
    "            ê²°ê³¼ ì €ì¥ ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        print(f\"\\nğŸ” ê²€ì¶œ ì‹œì‘: {Path(image_path).name}\")\n",
    "        print(f\"   ëª¨ë“œ: {mode}, ë„ë©”ì¸: {domain or 'general'}\")\n",
    "        \n",
    "        # ëª¨ë“œ ìë™ ì„ íƒ\n",
    "        if mode == 'auto':\n",
    "            mode = self._select_optimal_mode(image_path)\n",
    "        \n",
    "        # ëª¨ë“œë³„ ê²€ì¶œ ìˆ˜í–‰\n",
    "        if mode == 'fast':\n",
    "            results = self._fast_detection(image_path)\n",
    "        elif mode == 'accurate':\n",
    "            results = self._accurate_detection(image_path)\n",
    "        elif mode == 'segmentation':\n",
    "            results = self._segmentation_detection(image_path)\n",
    "        else:  # balanced\n",
    "            results = self._balanced_detection(image_path)\n",
    "        \n",
    "        # ë„ë©”ì¸ íŠ¹í™” í›„ì²˜ë¦¬\n",
    "        if domain:\n",
    "            results = self._apply_domain_filter(results, domain)\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        if save_results:\n",
    "            self._save_results(image_path, results, mode, domain)\n",
    "        \n",
    "        # ê¸°ë¡ ì¶”ê°€\n",
    "        self.detection_history.append({\n",
    "            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'image': image_path,\n",
    "            'mode': mode,\n",
    "            'domain': domain,\n",
    "            'detections': len(results.get('detections', []))\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _select_optimal_mode(self, image_path):\n",
    "        \"\"\"\n",
    "        ì´ë¯¸ì§€ íŠ¹ì„±ì— ë”°ë¼ ìµœì  ëª¨ë“œ ìë™ ì„ íƒ\n",
    "        \"\"\"\n",
    "        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¥¸ ëª¨ë“œ ì„ íƒ\n",
    "        if width * height > 1920 * 1080:\n",
    "            return 'fast'  # í° ì´ë¯¸ì§€ëŠ” ë¹ ë¥¸ ëª¨ë“œ\n",
    "        elif width * height < 640 * 480:\n",
    "            return 'accurate'  # ì‘ì€ ì´ë¯¸ì§€ëŠ” ì •í™•í•œ ëª¨ë“œ\n",
    "        else:\n",
    "            return 'balanced'  # ì¤‘ê°„ í¬ê¸°ëŠ” ê· í˜• ëª¨ë“œ\n",
    "    \n",
    "    def _fast_detection(self, image_path):\n",
    "        \"\"\"ë¹ ë¥¸ ê²€ì¶œ (nano ëª¨ë¸)\"\"\"\n",
    "        model = YOLO('yolo11n.pt')\n",
    "        results = model(image_path, conf=0.5, verbose=False)\n",
    "        return self._parse_results(results[0])\n",
    "    \n",
    "    def _balanced_detection(self, image_path):\n",
    "        \"\"\"ê· í˜•ì¡íŒ ê²€ì¶œ (medium ëª¨ë¸)\"\"\"\n",
    "        results = self.base_model(image_path, conf=0.45, verbose=False)\n",
    "        return self._parse_results(results[0])\n",
    "    \n",
    "    def _accurate_detection(self, image_path):\n",
    "        \"\"\"ì •í™•í•œ ê²€ì¶œ (ì•™ìƒë¸”)\"\"\"\n",
    "        ensemble_results = self.ensemble.ensemble_detect(image_path)\n",
    "        return {'detections': ensemble_results, 'mode': 'ensemble'}\n",
    "    \n",
    "    def _segmentation_detection(self, image_path):\n",
    "        \"\"\"ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²€ì¶œ\"\"\"\n",
    "        seg_results = self.segmentation.segment_image(image_path)\n",
    "        return {'detections': seg_results, 'mode': 'segmentation'}\n",
    "    \n",
    "    def _parse_results(self, results):\n",
    "        \"\"\"ê²°ê³¼ íŒŒì‹±\"\"\"\n",
    "        detections = []\n",
    "        \n",
    "        if results.boxes is not None:\n",
    "            for box in results.boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                cls_id = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                \n",
    "                detections.append({\n",
    "                    'bbox': [float(x1), float(y1), float(x2), float(y2)],\n",
    "                    'class': results.names[cls_id],\n",
    "                    'confidence': conf\n",
    "                })\n",
    "        \n",
    "        return {'detections': detections}\n",
    "    \n",
    "    def _apply_domain_filter(self, results, domain):\n",
    "        \"\"\"ë„ë©”ì¸ í•„í„° ì ìš©\"\"\"\n",
    "        # ë„ë©”ì¸ë³„ ê´€ì‹¬ í´ë˜ìŠ¤\n",
    "        domain_classes = {\n",
    "            'traffic': ['person', 'car', 'bus', 'truck', 'traffic light'],\n",
    "            'indoor': ['person', 'chair', 'laptop', 'tv', 'couch'],\n",
    "            'outdoor': ['person', 'bicycle', 'car', 'dog', 'bird']\n",
    "        }\n",
    "        \n",
    "        if domain in domain_classes:\n",
    "            target_classes = domain_classes[domain]\n",
    "            filtered = [d for d in results['detections'] \n",
    "                       if d['class'] in target_classes]\n",
    "            results['detections'] = filtered\n",
    "            results['domain_filtered'] = True\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _save_results(self, image_path, results, mode, domain):\n",
    "        \"\"\"ê²°ê³¼ ì €ì¥\"\"\"\n",
    "        # ê²°ê³¼ í´ë” ìƒì„±\n",
    "        output_dir = Path('detection_results')\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€\n",
    "        timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "        base_name = Path(image_path).stem\n",
    "        \n",
    "        # JSONìœ¼ë¡œ ì €ì¥\n",
    "        json_path = output_dir / f\"{base_name}_{timestamp}.json\"\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump({\n",
    "                'image': str(image_path),\n",
    "                'mode': mode,\n",
    "                'domain': domain,\n",
    "                'timestamp': timestamp,\n",
    "                'results': results\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        print(f\"   ğŸ’¾ ê²°ê³¼ ì €ì¥: {json_path}\")\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        ê²€ì¶œ ê¸°ë¡ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        \"\"\"\n",
    "        if not self.detection_history:\n",
    "            print(\"ê²€ì¶œ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ“Š ê²€ì¶œ ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        df = pd.DataFrame(self.detection_history)\n",
    "        \n",
    "        print(f\"\\nì´ ê²€ì¶œ ìˆ˜í–‰: {len(df)}íšŒ\")\n",
    "        print(f\"í‰ê·  ê²€ì¶œ ê°ì²´ ìˆ˜: {df['detections'].mean():.1f}ê°œ\")\n",
    "        \n",
    "        print(\"\\nëª¨ë“œë³„ ì‚¬ìš© ë¹ˆë„:\")\n",
    "        mode_counts = df['mode'].value_counts()\n",
    "        for mode, count in mode_counts.items():\n",
    "            print(f\"  â€¢ {mode}: {count}íšŒ\")\n",
    "        \n",
    "        print(\"\\nìµœê·¼ ê²€ì¶œ ê¸°ë¡:\")\n",
    "        for _, record in df.tail(3).iterrows():\n",
    "            print(f\"  {record['timestamp']}: {Path(record['image']).name} \"\n",
    "                 f\"({record['detections']} objects)\")\n",
    "\n",
    "# í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\nğŸ¯ í†µí•© ê²€ì¶œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "system = IntegratedDetectionSystem()\n",
    "\n",
    "if sample_images:\n",
    "    # ë‹¤ì–‘í•œ ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸\n",
    "    test_configs = [\n",
    "        ('fast', None),\n",
    "        ('balanced', 'traffic'),\n",
    "        ('accurate', None),\n",
    "    ]\n",
    "    \n",
    "    for mode, domain in test_configs:\n",
    "        results = system.detect(\n",
    "            sample_images[0],\n",
    "            mode=mode,\n",
    "            domain=domain,\n",
    "            save_results=True\n",
    "        )\n",
    "        print(f\"   ê²€ì¶œ ì™„ë£Œ: {len(results['detections'])} objects\\n\")\n",
    "    \n",
    "    # ë¦¬í¬íŠ¸ ìƒì„±\n",
    "    system.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ë§ˆë¬´ë¦¬ ë° í•µì‹¬ ì •ë¦¬\n",
    "\n",
    "### ğŸ“ í•™ìŠµí•œ ë‚´ìš© ì •ë¦¬\n",
    "\n",
    "1. **YOLO11 ê¸°ë³¸**\n",
    "   - 5ê°€ì§€ ëª¨ë¸ í¬ê¸° (nano ~ xlarge)\n",
    "   - ì†ë„ì™€ ì •í™•ë„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„\n",
    "   - GPU í™œìš©ë²•\n",
    "\n",
    "2. **ê³ ê¸‰ ê¸°ë²•**\n",
    "   - **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ\n",
    "   - **ì„¸ê·¸ë©˜í…Œì´ì…˜**: í”½ì…€ ë‹¨ìœ„ ì •ë°€ ê²€ì¶œ\n",
    "   - **ë„ë©”ì¸ íŠ¹í™”**: íŠ¹ì • ìš©ë„ ìµœì í™”\n",
    "\n",
    "3. **ì‹¤ë¬´ ì‘ìš©**\n",
    "   - êµí†µ ëª¨ë‹ˆí„°ë§\n",
    "   - ë³´ì•ˆ ê°ì‹œ\n",
    "   - ë¦¬í…Œì¼ ë¶„ì„\n",
    "\n",
    "### ğŸ’¡ í•µì‹¬ íŒ\n",
    "\n",
    "```python\n",
    "# ìš©ë„ë³„ ìµœì  ì„¤ì •\n",
    "settings = {\n",
    "    'ì‹¤ì‹œê°„': {'model': 'yolo11n.pt', 'conf': 0.5},\n",
    "    'ê· í˜•': {'model': 'yolo11m.pt', 'conf': 0.45},\n",
    "    'ì •í™•ë„': {'model': 'ensemble', 'conf': 0.4},\n",
    "    'ì„¸ë°€í•¨': {'model': 'yolo11x-seg.pt', 'conf': 0.5}\n",
    "}\n",
    "```\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í•™ìŠµ**\n",
    "   - ìì‹ ë§Œì˜ ê°ì²´ í´ë˜ìŠ¤ ì •ì˜\n",
    "   - ë°ì´í„° ë¼ë²¨ë§\n",
    "   - ëª¨ë¸ íŒŒì¸íŠœë‹\n",
    "\n",
    "2. **ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ êµ¬ì¶•**\n",
    "   - ì›¹ìº  ì—°ë™\n",
    "   - ìŠ¤íŠ¸ë¦¬ë° ì„œë²„\n",
    "   - ì›¹ ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "3. **í”„ë¡œë•ì…˜ ë°°í¬**\n",
    "   - Docker ì»¨í…Œì´ë„ˆí™”\n",
    "   - API ì„œë²„ êµ¬ì¶•\n",
    "   - í´ë¼ìš°ë“œ ë°°í¬\n",
    "\n",
    "### ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ\n",
    "\n",
    "- [Ultralytics Documentation](https://docs.ultralytics.com/)\n",
    "- [YOLO11 GitHub](https://github.com/ultralytics/ultralytics)\n",
    "- [Computer Vision Course](https://www.coursera.org/learn/computer-vision-basics)\n",
    "\n",
    "---\n",
    "\n",
    "**ì‘ì„±ì**: aebonlee  \n",
    "**GitHub**: [YOLO11_study](https://github.com/aebonlee/YOLO11_study)  \n",
    "**License**: MIT\n",
    "\n",
    "ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ GitHub Issuesì— ë‚¨ê²¨ì£¼ì„¸ìš”! ğŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë…¸íŠ¸ë¶ ì™„ë£Œ ë©”ì‹œì§€\n",
    "print(\"ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! YOLO11 ê³ ê¸‰ íŠœí† ë¦¬ì–¼ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"\\nì´ì œ ë‹¹ì‹ ì€:\")\n",
    "print(\"âœ… YOLO11ì˜ ë‹¤ì–‘í•œ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "print(\"âœ… ì•™ìƒë¸”ê³¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "print(\"âœ… ë„ë©”ì¸ íŠ¹í™” ê²€ì¶œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "print(\"âœ… ì„±ëŠ¥ ìµœì í™”ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "print(\"\\nğŸš€ ì´ì œ ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}